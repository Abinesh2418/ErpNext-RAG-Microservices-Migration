# Copy this file to .env and fill in your values

# Groq API Configuration
GROQ_API_KEY=your_groq_api_key
GROQ_MODEL=your_groq_model # Preferred Groq model llama-3.3-70b-versatile

# LLM Temperature (0.0-1.0, lower = more deterministic)
AI_TEMPERATURE=0.2

# Parallel Worker Configuration
PRIMARY_WORKERS=4

# ollama configuration 
OLLAMA_BASE_URL=your_ollama_url # e.g., http://localhost:11434
OLLAMA_EMBED_MODEL=your_embed_model # Preferred embedding model nomic-embed-text:v1.5

# REDIS CONFIGURATION (for caching & structure)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0

# QDRANT CONFIGURATION (Local Docker/Native)
QDRANT_HOST=localhost
QDRANT_PORT=6333

# Conversion Settings
MAX_FILE_SIZE_MB=10
ENABLE_SYNTAX_CHECK=true
