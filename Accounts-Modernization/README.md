# Accounts-Modernization

**CLI-based Python â†’ Go conversion system powered by Groq API with Redis caching and Qdrant semantic search**

Automates the conversion of ERPNext Accounts module from Python to Go with intelligent caching, semantic context, and comprehensive validation.

---

## ğŸ“‘ Table of Contents

- [Project Overview](#-project-overview)
- [Project Description](#-project-description)
- [Architecture Principles](#-architecture-principles)
- [Project Structure](#-project-structure)
- [Getting Started](#-getting-started)
  - [Prerequisites](#prerequisites)
  - [Installation](#installation)
  - [Configuration](#configuration)
- [Usage](#-usage)
- [Testing](#-testing)
- [How It Works](#-how-it-works)
- [Technology Stack](#-technology-stack)
- [Troubleshooting](#-troubleshooting)
- [Documentation](#-documentation)
- [Contact](#-contact)

---

## ğŸ¯ Project Overview

Accounts-Modernization is a production-ready, CLI-based conversion system that automates the transformation of ERPNext's Python-based Accounts module into idiomatic, production-ready Go code. The system leverages Groq's powerful LLM API (llama-3.3-70b-versatile) for intelligent code conversion while maintaining business logic integrity through comprehensive validation.

**Key Capabilities:**

âœ… **Intelligent Analysis** - Python AST-based static code analysis  
âœ… **Smart Caching** - Redis-based caching for instant re-conversion (600x faster)  
âœ… **Semantic Context** - Qdrant vector database for meaning-based context retrieval  
âœ… **AI-Powered Conversion** - Groq API with llama-3.3-70b-versatile model  
âœ… **Comprehensive Validation** - Automated Go syntax and compilation checks  
âœ… **Business Logic Preservation** - Zero data integrity loss with accounting rules intact  

---

## ğŸ“‹ Project Description

### The Challenge

Converting a complex accounting ERP system from Python to Go while:
- Preserving intricate business logic (invoice management, ledger entries, tax calculations)
- Maintaining data integrity and accounting rules
- Ensuring production-ready code quality
- Minimizing manual intervention and review time

### The Solution

A sophisticated 5-phase conversion pipeline:

1. **Static Analysis** - AST-based code understanding without execution
2. **Smart Caching** - SHA-256 hash-based change detection with Redis
3. **Semantic Indexing** - Ollama-powered embeddings stored in Qdrant (768-dimensional vectors)
4. **AI Conversion** - Groq API (llama-3.3-70b-versatile) with context-aware prompts
5. **Automated Validation** - Go compiler checks and syntax validation

### Key Features

- **ğŸš€ Speed**: First run ~54s/file, cached runs ~0.05s/file (600x improvement)
- **ğŸ¯ Quality**: High-parameter model (70B) for superior code generation
- **ğŸ”„ Incremental**: Only converts changed files, preserves cache for others
- **ğŸ§  Context-Aware**: Semantic search provides relevant code examples to AI
- **âœ… Validated**: Every conversion is syntax-checked and compilation-tested
- **ğŸ“Š Transparent**: Complete audit trail with detailed logs and reports

---

## ğŸ—ï¸ Architecture Principles

| Component | Role | Purpose |
|-----------|------|---------|
| **Python AST** | Truth Provider | Provides structural facts without code execution |
| **Redis** | Structure & Speed | Caches hashes, AST, dependencies, conversions |
| **Qdrant** | Semantic Memory | Stores code meanings for context retrieval |
| **Ollama** | Embedding Generator | Local embeddings (nomic-embed-text:v1.5, 768-dim) |
| **Groq API** | AI Translator | Converts code using llama-3.3-70b-versatile |
| **Go Compiler** | Quality Gate | Validates generated code |

**Conversion Flow**: AST analyzes â†’ Redis caches â†’ Qdrant provides context â†’ Groq converts â†’ Go validates

---

## ğŸ“ Project Structure

```
Accounts-Modernization/
â”œâ”€â”€ cli/                           # CLI entry point
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ main.py                   # Main CLI command
â”‚
â”œâ”€â”€ backend/                      # Core conversion logic
â”‚   â”œâ”€â”€ analyzer/                 # Static analysis & caching
â”‚   â”‚   â”œâ”€â”€ scanner.py            # File discovery & syntax check
â”‚   â”‚   â”œâ”€â”€ dependency_analyzer.py # AST-based dependency extraction
â”‚   â”‚   â”œâ”€â”€ redis_store.py        # ğŸ†• Redis cache layer
â”‚   â”‚   â””â”€â”€ qdrant_index.py       # ğŸ†• Semantic index
â”‚   â”‚
â”‚   â”œâ”€â”€ converter/                # Python â†’ Go conversion
â”‚   â”‚   â””â”€â”€ ai_converter.py       # AI conversion with caching
â”‚   â”‚
â”‚   â””â”€â”€ utils/                    # Configuration & logging
â”‚       â”œâ”€â”€ config.py
â”‚       â””â”€â”€ logger.py
â”‚
â”œâ”€â”€ modern/                       # ğŸ“¦ Generated Go code
â”‚   â”œâ”€â”€ invoice/                  # Go invoice module
â”‚   â”œâ”€â”€ ledger/                   # Go ledger module
â”‚   â”œâ”€â”€ tax/                      # Go tax module
â”‚   â”œâ”€â”€ party/                    # Go party module
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ tests/                        # ğŸ§ª Multi-level testing
â”‚   â”œâ”€â”€ unit/                     # Go compilation & syntax tests
â”‚   â”œâ”€â”€ integration/              # Module integration tests
â”‚   â”œâ”€â”€ functional/               # Accounting scenario tests
â”‚   â””â”€â”€ qa_validation/            # Automated QA validation
â”‚
â”œâ”€â”€ logs/                         # ğŸ“‹ Runtime logs
â”‚   â”œâ”€â”€ scan_*.log
â”‚   â”œâ”€â”€ dependency_*.log
â”‚   â””â”€â”€ conversion_*.log
â”‚
â”œâ”€â”€ results/                      # ğŸ“Š Reports & metrics
â”‚   â”œâ”€â”€ conversion_report_*.txt
â”‚   â””â”€â”€ qa_report_*.txt
â”‚
â”œâ”€â”€ ARCHITECTURE.md               # Detailed system architecture
â”œâ”€â”€ ARCHITECTURE_REDIS_QDRANT_SECTIONS.md  # New sections on caching
â”œâ”€â”€ SYSTEM_DESIGN.md              # System design document
â””â”€â”€ README.md                     # This file
```

---

## ğŸš€ Getting Started

### Prerequisites

1. **Python 3.8+** - Core runtime
2. **Groq API Key** - For AI conversion ([Get key](https://console.groq.com))
3. **Ollama** - For local embeddings generation
4. **Redis 5.0+** - For caching
5. **Qdrant 1.7.0+** - For semantic search
6. **Go 1.19+** - For validating generated code

### Installation

#### 1. Install Python Dependencies

```bash
cd d:\Internships\PearlThoughts-Internship\Erpnext-Refactoring
pip install -r requirements.txt
```

This installs:
- `python-dotenv` - Environment variable management
- `redis` - Redis client for caching
- `qdrant-client` - Qdrant vector database client
- `requests` - HTTP client for Groq API
- `astroid` - Advanced AST analysis

#### 2. Get Groq API Key

1. Visit [Groq Console](https://console.groq.com)
2. Sign up or log in
3. Create a new API key
4. Copy the key (starts with `gsk_...`)

#### 3. Install and Start Ollama (for embeddings)

**Windows:**
```bash
# Download from https://ollama.ai/download
# Install and run Ollama

# Pull embedding model only
ollama pull nomic-embed-text:v1.5
```

**Linux/Mac:**
```bash
# Install Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Pull embedding model
ollama pull nomic-embed-text:v1.5

# Start Ollama service
ollama serve
```

#### 4. Start Redis

**Windows:**
```bash
# Download from https://redis.io/download
# Or use Docker:
docker run -d -p 6379:6379 redis:latest
```

**Linux/Mac:**
```bash
sudo service redis-server start
# Or: redis-server
```

#### 5. Start Qdrant

**Docker (Recommended):**
```bash
docker run -d -p 6333:6333 qdrant/qdrant
```

**Or download from:** https://qdrant.tech/documentation/quick-start/

#### 6. Configure Environment

Create a `.env` file in the **root directory** (Erpnext-Refactoring/):

```bash
# Groq API Configuration (for AI conversion)
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=llama-3.3-70b-versatile

# Ollama Configuration (for embeddings only)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_EMBED_MODEL=nomic-embed-text:v1.5

# Redis Configuration
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0

# Qdrant Configuration
QDRANT_HOST=localhost
QDRANT_PORT=6333

# Conversion Settings
AI_TEMPERATURE=0.2
PRIMARY_WORKERS=4
MAX_FILE_SIZE_MB=10
ENABLE_SYNTAX_CHECK=true
```

**âš ï¸ Important**: The `.env` file must be in the **root directory** (Erpnext-Refactoring/), not in Accounts-Modernization/

---

## ğŸ’» Usage

### Convert Python Files to Go

#### Single File
```bash
cd Accounts-Modernization
python cli/main.py convert ../accounts/party.py
```

#### Entire Folder
```bash
python cli/main.py convert ../accounts/
```

#### With Absolute Path
```bash
python cli/main.py convert "D:\path\to\accounts\"
```

### What Happens During Conversion?

```
1. ğŸ“‚ SCAN: Discover Python files
   â””â”€â–º Validate syntax using Python AST
   â””â”€â–º Extract file metadata (size, lines, etc.)
       
2. ğŸ” ANALYZE: AST-based code understanding
   â””â”€â–º Extract imports, classes, functions
   â””â”€â–º Build dependency graph
   â””â”€â–º Check Redis for cached AST
       â””â”€â–º If found: Reuse cached analysis
       â””â”€â–º If new: Analyze and cache in Redis
   
3. ğŸ•¸ï¸ INDEX: Semantic meaning storage
   â””â”€â–º Generate embeddings using Ollama (768-dim vectors)
   â””â”€â–º Store file & function meanings in Qdrant
   â””â”€â–º Enable context-aware conversion
   
4. ğŸ¤– CONVERT: AI-powered Python â†’ Go
   â””â”€â–º Check Redis cache (SHA-256 hash)
       â””â”€â–º If file unchanged: Use cached Go code (0.05s)
       â””â”€â–º If changed: Proceed with conversion
   â””â”€â–º Fetch relevant context from Qdrant (top-3 matches)
   â””â”€â–º Build enhanced prompt with business rules
   â””â”€â–º Call Groq API (llama-3.3-70b-versatile)
   â””â”€â–º Stream response with early stop detection
   â””â”€â–º Extract and clean Go code
   â””â”€â–º Cache result in Redis for future runs
   
5. âœ… VALIDATE: Quality checks
   â””â”€â–º Go syntax validation (gofmt)
   â””â”€â–º Compilation test (go build)
   â””â”€â–º Generate conversion report
   
6. ğŸ’¾ SAVE: Write Go files
   â””â”€â–º Organize into modules (party/, invoice/, ledger/, etc.)
   â””â”€â–º Save to modern/ directory
```

### Performance

**First Conversion (No Cache):**
- Small file (100 lines): ~15-20 seconds
- Medium file (500 lines): ~30-40 seconds  
- Large file (1000+ lines): ~50-60 seconds

**Cached Conversion (File Unchanged):**
- Any size: ~0.05 seconds (âš¡ **600x faster**)

**Typical 50-File Project:**
- First run: ~40-45 minutes
- Second run (2 files changed): ~3-5 minutes (ğŸš€ **15x faster**)

### View Conversion Results

```bash
# Check generated Go code
ls modern/

# View conversion report
cat results/conversion_report_TIMESTAMP.txt

# Check logs
cat logs/conversion_TIMESTAMP.log
```

---

## ğŸ§ª Testing

### Validate Conversion with go_test.py

```bash
cd Accounts-Modernization

# Test Groq API connection
python go_test.py api

# Validate Go syntax
python go_test.py syntax

# Test Go compilation
python go_test.py compile

# Test conversion pipeline on a file
python go_test.py convert ../accounts/party.py

# Analyze conversion results
python go_test.py results

# Run all tests
python go_test.py all
```

### Test Coverage

- **API Connection**: Validates Groq API connectivity and authentication
- **Syntax Validation**: Checks all generated Go files for syntax errors (gofmt)
- **Compilation**: Verifies Go code compiles successfully (go build)
- **Conversion Pipeline**: End-to-end testing of Pythonâ†’Go conversion
- **Results Analysis**: Reviews conversion reports and metrics

---

## ğŸ”§ Technology Stack

| Component | Technology | Purpose |
|-----------|-----------|---------||
| **Language** | Python 3.8+ | Analysis & orchestration |
| **AST Parser** | Python `ast` / `astroid` | Static code analysis |
| **Cache** | Redis 5.0+ | Structure, dependencies & conversion cache |
| **Vector DB** | Qdrant 1.7.0+ | Semantic search (768-dimensional) |
| **Embeddings** | Ollama (nomic-embed-text:v1.5) | Local vector generation |
| **AI Conversion** | Groq API (llama-3.3-70b-versatile) | Python â†’ Go conversion |
| **Target Language** | Go 1.19+ | Output language |
| **Validation** | Go compiler (gofmt, go build) | Code quality assurance |
| **Environment** | python-dotenv | Configuration management |

### Key Technologies

**Groq API:**
- Model: llama-3.3-70b-versatile (70B parameters)
- Context window: 131,072 tokens
- Temperature: 0.2 (deterministic output)
- Streaming API support for faster response
- High-performance inference

**Redis:**
- File hash storage (SHA-256)
- AST results caching
- Dependency graph storage
- Conversion output caching

**Qdrant:**
- 768-dimensional vector storage
- Semantic similarity search
- File and function meaning indexing
- Fast context retrieval for AI prompts

**Ollama:**
- Local embedding generation
- Model: nomic-embed-text:v1.5
- Fast, privacy-preserving vector creation

---

## ğŸ“ How It Works

### Complete 5-Phase Conversion Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 1: SCAN & VALIDATE (2-5 seconds)                       â”‚
â”‚  â€¢ Discover .py files recursively                              â”‚
â”‚  â€¢ Validate Python syntax using AST                            â”‚
â”‚  â€¢ Extract metadata (size, lines, etc.)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 2: AST ANALYSIS (5-10 seconds/file)                    â”‚
â”‚  â€¢ Parse Python AST (Abstract Syntax Tree)                     â”‚
â”‚  â€¢ Extract imports, classes, functions                         â”‚
â”‚  â€¢ Build dependency graph                                      â”‚
â”‚  â€¢ Cache results in Redis (for next run)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 3: SEMANTIC INDEXING (1-2 min, one-time)               â”‚
â”‚  â€¢ Generate embeddings using Ollama (768-dim)                  â”‚
â”‚  â€¢ Store file meanings in Qdrant                               â”‚
â”‚  â€¢ Store function meanings in Qdrant                           â”‚
â”‚  â€¢ Enable semantic context retrieval                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 4: AI CONVERSION (10-30s OR 0.05s cached)               â”‚
â”‚  â€¢ Check Redis cache (SHA-256 hash)                            â”‚
â”‚      â””â”€ Unchanged? Return cached Go code (0.05s)              â”‚
â”‚  â€¢ Query Qdrant for relevant context (top-3)                   â”‚
â”‚  â€¢ Build enhanced prompt with business rules                   â”‚
â”‚  â€¢ Call Groq API (llama-3.3-70b-versatile)                    â”‚
â”‚  â€¢ Stream response with early stop detection                   â”‚
â”‚  â€¢ Extract & validate Go code                                  â”‚
â”‚  â€¢ Cache result in Redis                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 5: VALIDATE & SAVE (5-10 seconds)                      â”‚
â”‚  â€¢ Validate Go syntax (gofmt)                                  â”‚
â”‚  â€¢ Test compilation (go build)                                 â”‚
â”‚  â€¢ Organize into modules (party/, invoice/, etc.)             â”‚
â”‚  â€¢ Write to modern/ directory                                  â”‚
â”‚  â€¢ Generate conversion report                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Incremental Conversion with Caching

For each Python file, the system:

```python
# 1. Compute file hash
file_hash = SHA256(file_content)

# 2. Check Redis cache
if redis.get(f"conversion:{file_path}") and redis.get(f"hash:{file_path}") == file_hash:
    # File unchanged - use cached Go code
    go_code = redis.get(f"conversion:{file_path}")
    return go_code  # âš¡ 0.05 seconds!

# 3. File changed or new - convert
go_code = convert_with_groq_api(file_content, context)

# 4. Cache for future
redis.set(f"conversion:{file_path}", go_code)
redis.set(f"hash:{file_path}", file_hash)
```

### Context-Aware Conversion

```python
# For file: party.py

# 1. Query Qdrant for semantic context
context = qdrant.search(
    query="party management customer supplier accounting",
    top_k=3
)
# Returns:
# - File party.py: Party management (score: 0.89)
# - Function get_party_balance: Calculate outstanding (score: 0.76) 
# - Links to general_ledger.py (score: 0.68)

# 2. Build enhanced prompt
prompt = f"""
Convert this Python code to Go.

RELEVANT CONTEXT:
{context}

PYTHON CODE:
{python_code}

REQUIREMENTS:
- Preserve business logic
- Use idiomatic Go patterns
- Add error handling
"""

# 3. Call Groq API
response = groq.chat.completions.create(
    model="llama-3.3-70b-versatile",
    messages=[{"role": "user", "content": prompt}],
    temperature=0.2,
    stream=True
)
```

### Benefits

âœ… **600x Faster**: Cached conversions (0.05s vs 30s)  
âœ… **Context-Aware**: Relevant code examples automatically included  
âœ… **Incremental**: Only converts changed files  
âœ… **Quality**: 70B parameter model for superior output  
âœ… **Validated**: Every conversion tested for syntax and compilation

---

## ğŸš§ Troubleshooting

### Redis Connection Failed
```bash
# Check Redis is running
redis-cli ping
# Should return: PONG

# If not running, start Redis:
# Windows: redis-server.exe
# Linux: sudo service redis-server start
```

### Qdrant Connection Failed
```bash
# Check Qdrant is running
curl http://localhost:6333

# If not running:
docker run -d -p 6333:6333 qdrant/qdrant
```

### Ollama Not Responding (For Embeddings)
```bash
# Check Ollama is running
curl http://localhost:11434

# Start Ollama service:
# Windows: Ollama should auto-start
# Linux/Mac: ollama serve

# Verify embedding model is installed:
ollama list

# Pull embedding model if missing:
ollama pull nomic-embed-text:v1.5
```

### Groq API Issues
```bash
# Check API key is set in .env file (root directory)
grep GROQ_API_KEY ../. env

# Test API connection:
python go_test.py api

# Verify model availability:
# Visit: https://console.groq.com/
```

---

## ï¿½ Documentation

- **[ARCHITECTURE.md](ARCHITECTURE.md)** - Complete system architecture and design
- **[CONVERSION_FLOW.md](CONVERSION_FLOW.md)** - Detailed conversion flow walkthrough with code references
---

## ğŸ™ Acknowledgments

- **ERPNext** - Source accounting system providing the Python codebase
- **Groq** - High-performance LLM API infrastructure
- **Meta AI** - LLaMA 3.3 foundation model (70B parameters)
- **Ollama** - Local embedding generation runtime
- **Redis Labs** - High-performance in-memory caching
- **Qdrant** - Vector similarity search engine
- **Go Team** - Target language and compiler

---

## ğŸ“¬ Contact

For queries or suggestions:

- ğŸ“§ **Email**: abineshbalasubramaniyam@example.com  
- ğŸ’¼ **LinkedIn**: [Abinesh B](https://linkedin.com/in/abinesh-b-1b14a1290/)  
- ğŸ™ **GitHub**: [Abinesh2418](https://github.com/Abinesh2418)

---
